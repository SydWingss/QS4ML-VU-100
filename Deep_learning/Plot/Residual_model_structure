digraph {
	graph [size="19.2,19.2"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1673172269664 [label="
 (1, 4)" fillcolor=darkolivegreen1]
	1673159228384 [label=SoftmaxBackward0]
	1673159226224 -> 1673159228384
	1673159226224 [label=AddmmBackward0]
	1673159227568 -> 1673159226224
	1673172269184 [label="layer.5.bias
 (4)" fillcolor=lightblue]
	1673172269184 -> 1673159227568
	1673159227568 [label=AccumulateGrad]
	1673159222624 -> 1673159226224
	1673159222624 [label=MulBackward0]
	1673165693536 -> 1673159222624
	1673165693536 [label=AddBackward0]
	1673170925168 -> 1673165693536
	1673170925168 [label=MulBackward0]
	1673171098432 -> 1673170925168
	1673171098432 [label=ReluBackward0]
	1673171208752 -> 1673171098432
	1673171208752 [label=AddmmBackward0]
	1673171217680 -> 1673171208752
	1673172268784 [label="layer.3.linear.bias
 (32)" fillcolor=lightblue]
	1673172268784 -> 1673171217680
	1673171217680 [label=AccumulateGrad]
	1673171215520 -> 1673171208752
	1673171215520 [label=AddBackward0]
	1673160264816 -> 1673171215520
	1673160264816 [label=MulBackward0]
	1673160265008 -> 1673160264816
	1673160265008 [label=ReluBackward0]
	1673160265152 -> 1673160265008
	1673160265152 [label=AddmmBackward0]
	1673160264960 -> 1673160265152
	1673172268464 [label="layer.2.linear.bias
 (64)" fillcolor=lightblue]
	1673172268464 -> 1673160264960
	1673160264960 [label=AccumulateGrad]
	1673160264912 -> 1673160265152
	1673160264912 [label=AddBackward0]
	1673160266736 -> 1673160264912
	1673160266736 [label=MulBackward0]
	1673160267744 -> 1673160266736
	1673160267744 [label=ReluBackward0]
	1673160267456 -> 1673160267744
	1673160267456 [label=AddmmBackward0]
	1673160266976 -> 1673160267456
	1673172268304 [label="layer.1.linear.bias
 (128)" fillcolor=lightblue]
	1673172268304 -> 1673160266976
	1673160266976 [label=AccumulateGrad]
	1673160266784 -> 1673160267456
	1673160266784 [label=AddBackward0]
	1673160267024 -> 1673160266784
	1673160267024 [label=MulBackward0]
	1673160266592 -> 1673160267024
	1673160266592 [label=ReluBackward0]
	1673160267216 -> 1673160266592
	1673160267216 [label=AddmmBackward0]
	1673160267552 -> 1673160267216
	1673172267984 [label="layer.0.linear.bias
 (128)" fillcolor=lightblue]
	1673172267984 -> 1673160267552
	1673160267552 [label=AccumulateGrad]
	1673160267648 -> 1673160267216
	1673160267648 [label=TBackward0]
	1673160267600 -> 1673160267648
	1673172267104 [label="layer.0.linear.weight
 (128, 232)" fillcolor=lightblue]
	1673172267104 -> 1673160267600
	1673160267600 [label=AccumulateGrad]
	1673160268080 -> 1673160266784
	1673160268080 [label=AddmmBackward0]
	1673160266400 -> 1673160268080
	1673172268144 [label="layer.0.linear_shortcut.bias
 (128)" fillcolor=lightblue]
	1673172268144 -> 1673160266400
	1673160266400 [label=AccumulateGrad]
	1673160267168 -> 1673160268080
	1673160267168 [label=TBackward0]
	1673160267408 -> 1673160267168
	1673172268064 [label="layer.0.linear_shortcut.weight
 (128, 232)" fillcolor=lightblue]
	1673172268064 -> 1673160267408
	1673160267408 [label=AccumulateGrad]
	1673160267696 -> 1673160267456
	1673160267696 [label=TBackward0]
	1673160267312 -> 1673160267696
	1673172268224 [label="layer.1.linear.weight
 (128, 128)" fillcolor=lightblue]
	1673172268224 -> 1673160267312
	1673160267312 [label=AccumulateGrad]
	1673160266784 -> 1673160264912
	1673160264720 -> 1673160265152
	1673160264720 [label=TBackward0]
	1673160267504 -> 1673160264720
	1673172268384 [label="layer.2.linear.weight
 (64, 128)" fillcolor=lightblue]
	1673172268384 -> 1673160267504
	1673160267504 [label=AccumulateGrad]
	1673160264768 -> 1673171215520
	1673160264768 [label=AddmmBackward0]
	1673160266496 -> 1673160264768
	1673172268624 [label="layer.2.linear_shortcut.bias
 (64)" fillcolor=lightblue]
	1673172268624 -> 1673160266496
	1673160266496 [label=AccumulateGrad]
	1673160264912 -> 1673160264768
	1673160265104 -> 1673160264768
	1673160265104 [label=TBackward0]
	1673160266544 -> 1673160265104
	1673172268544 [label="layer.2.linear_shortcut.weight
 (64, 128)" fillcolor=lightblue]
	1673172268544 -> 1673160266544
	1673160266544 [label=AccumulateGrad]
	1673171212160 -> 1673171208752
	1673171212160 [label=TBackward0]
	1673160266448 -> 1673171212160
	1673172268704 [label="layer.3.linear.weight
 (32, 64)" fillcolor=lightblue]
	1673172268704 -> 1673160266448
	1673160266448 [label=AccumulateGrad]
	1673165691856 -> 1673165693536
	1673165691856 [label=AddmmBackward0]
	1673171210240 -> 1673165691856
	1673172268944 [label="layer.3.linear_shortcut.bias
 (32)" fillcolor=lightblue]
	1673172268944 -> 1673171210240
	1673171210240 [label=AccumulateGrad]
	1673171215520 -> 1673165691856
	1673171099872 -> 1673165691856
	1673171099872 [label=TBackward0]
	1673160265056 -> 1673171099872
	1673172268864 [label="layer.3.linear_shortcut.weight
 (32, 64)" fillcolor=lightblue]
	1673172268864 -> 1673160265056
	1673160265056 [label=AccumulateGrad]
	1673165685328 -> 1673159226224
	1673165685328 [label=TBackward0]
	1673171102416 -> 1673165685328
	1673172269024 [label="layer.5.weight
 (4, 32)" fillcolor=lightblue]
	1673172269024 -> 1673171102416
	1673171102416 [label=AccumulateGrad]
	1673159228384 -> 1673172269664
}
