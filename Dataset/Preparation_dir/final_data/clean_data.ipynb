{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy.spatial.transform import Slerp\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_merge_data_dir = os.getcwd() + '/raw_merge_data/'\n",
    "raw_merge_data_files = ['walk_merge_raw.csv', 'bike_merge_raw.csv', 'run_merge_raw.csv', 'sit_merge_raw.csv', 'syn_merge_raw.csv']\n",
    "\n",
    "#所有dataframe都存在这里\n",
    "df_list = []\n",
    "\n",
    "for i in range(len(raw_merge_data_files)):\n",
    "    df = pd.read_csv(raw_merge_data_dir + raw_merge_data_files[i], low_memory=False)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "清洗手环数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'rate' has NaN: False\n",
      "Column 'rateZone' has NaN: False\n",
      "Column 'BandAccZ' has NaN: False\n",
      "Column 'BandAccX' has NaN: False\n",
      "Column 'BandAccY' has NaN: False\n",
      "Column 'rate' has NaN: False\n",
      "Column 'rateZone' has NaN: False\n",
      "Column 'BandAccZ' has NaN: False\n",
      "Column 'BandAccX' has NaN: False\n",
      "Column 'BandAccY' has NaN: False\n",
      "Column 'rate' has NaN: False\n",
      "Column 'rateZone' has NaN: False\n",
      "Column 'BandAccZ' has NaN: False\n",
      "Column 'BandAccX' has NaN: False\n",
      "Column 'BandAccY' has NaN: False\n",
      "Column 'rate' has NaN: False\n",
      "Column 'rateZone' has NaN: False\n",
      "Column 'BandAccZ' has NaN: False\n",
      "Column 'BandAccX' has NaN: False\n",
      "Column 'BandAccY' has NaN: False\n",
      "Column 'rate' has NaN: False\n",
      "Column 'rateZone' has NaN: False\n",
      "Column 'BandAccZ' has NaN: False\n",
      "Column 'BandAccX' has NaN: False\n",
      "Column 'BandAccY' has NaN: False\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers_z_thresh(df, column, z_threshold=3): #基于正态分布Z分数的异常值去除\n",
    "\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    z_scores = (df[column] - mean) / std\n",
    "    df.loc[np.abs(z_scores) >= z_threshold, column] = np.nan\n",
    "    return df\n",
    "\n",
    "#经过我的测试，对于心率数据，线性插值，样条插值，多项式插值效果都非常接近，对于加速度数据，多项式插值效果最好\n",
    "\n",
    "columns_band = ['rate', 'rateZone', 'BandAccZ', 'BandAccX', 'BandAccY']\n",
    "\n",
    "\n",
    "for i in range(df_list.__len__()):\n",
    "    for column in columns_band:\n",
    "        df_list[i] = remove_outliers_z_thresh(df_list[i], column)\n",
    "        df_list[i][column] = df_list[i][column].interpolate(method='polynomial', order=3)#样条插值\n",
    "        df_list[i][column] = df_list[i][column].ffill().bfill()#前向填充，后向填充\n",
    "        has_nan = df_list[i][column].isnull().any()\n",
    "        print(f\"Column '{column}' has NaN: {has_nan}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "清洗手机系统数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34401, 29865, 12800, 14771, 37936]\n",
      "129773\n",
      "129773\n",
      "啦啦啦啦啦啦啦\n",
      "[34401, 29865, 12800, 14771, 37936]\n",
      "129773\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(df) for df in df_list]\n",
    "# 将lengths中的每个值相加到一起\n",
    "print(lengths)\n",
    "print(sum(lengths))\n",
    "# 读取df_list变量，将这个list按照df_list[0]、1、2、3、4的顺序纵向合并为一个dataframe，名为df_raw。\n",
    "df_raw = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "# 输出df_raw的行数\n",
    "print(len(df_raw))\n",
    "\n",
    "# 处理 'usage' 列的空值\n",
    "usage = 'use'\n",
    "for i, row in df_raw.iterrows():\n",
    "    if pd.isna(row['usage']):\n",
    "        df_raw.at[i, 'usage'] = usage\n",
    "    else:\n",
    "        usage = row['usage']\n",
    "        \n",
    "# 处理 'deviceStatus' 列的空值\n",
    "if pd.isna(df_raw.at[0, 'deviceStatus']):\n",
    "    df_raw.at[0, 'deviceStatus'] = 'ACTIVITY_PAUSED'\n",
    "\n",
    "df_raw['deviceStatus'] = df_raw['deviceStatus'].ffill()  # 向上填充\n",
    "\n",
    "# 根据 'lengths' 列表将 'df_raw' 分割成 'df_list'\n",
    "df_list = []\n",
    "start = 0\n",
    "for length in lengths:\n",
    "    df_list.append(df_raw.iloc[start:start+length])\n",
    "    start += length\n",
    "\n",
    "print(\"啦啦啦啦啦啦啦\")\n",
    "lengths = [len(df) for df in df_list]\n",
    "# 将lengths中的每个值相加到一起\n",
    "print(lengths)\n",
    "print(sum(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'usage' has NaN: False\n",
      "Column 'deviceStatus' has NaN: False\n",
      "Column 'usage' has NaN: False\n",
      "Column 'deviceStatus' has NaN: False\n",
      "Column 'usage' has NaN: False\n",
      "Column 'deviceStatus' has NaN: False\n",
      "Column 'usage' has NaN: False\n",
      "Column 'deviceStatus' has NaN: False\n",
      "Column 'usage' has NaN: False\n",
      "Column 'deviceStatus' has NaN: False\n"
     ]
    }
   ],
   "source": [
    "columns_band = ['usage', 'deviceStatus']\n",
    "for i in range(df_list.__len__()):\n",
    "    for column in columns_band:\n",
    "        has_nan = df_list[i][column].isnull().any()\n",
    "        print(f\"Column '{column}' has NaN: {has_nan}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "清洗MATLAB数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义清洗函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "# Define thresholds for specific columns\n",
    "thresholds = {\n",
    "    \"latitude\": (-90, 90),\n",
    "    \"longitude\": (-180, 180),\n",
    "    \"altitude\": (-500, 12000),\n",
    "    \"course\": (0, 360),\n",
    "    \"hacc\": (0, 100),  # Assuming max horizontal accuracy of 100 meters\n",
    "    \"speed\": (0, 300),  # Assuming max speed of 300 m/s\n",
    "\n",
    "}\n",
    "columns_to_check = [\n",
    "    \"altitude\",\n",
    "    \"course\",\n",
    "    \"hacc\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"speed\",\n",
    "\n",
    "]\n",
    "geolocation_columns = [\"altitude\", \"course\", \"latitude\", \"longitude\"]\n",
    "\n",
    "\n",
    "\n",
    "def remove_outliers_and_apply_thresholds(df, columns_to_check, thresholds): #移除异常值和阈值以外的值\n",
    "    for column in columns_to_check:\n",
    "        if column in df.columns:\n",
    "            threshold = thresholds.get(column, None)\n",
    "            if threshold is not None:\n",
    "                # Filter outliers, retain NaN values\n",
    "                df = df[(df[column].isna()) | ((df[column] >= threshold[0]) & (df[column] <= threshold[1]))]\n",
    "    return df\n",
    "\n",
    "def extract_XYZcolumns(df):#提XYZ和Type列\n",
    "    return df[[\"dateTime\", \"X\", \"Y\", \"Z\", \"Type\"]].copy()\n",
    "\n",
    "\n",
    "def extract_geolocation_columns(df):#提取地理位置列\n",
    "    return pd.concat([df[\"dateTime\"], df[geolocation_columns]], axis=1).copy()\n",
    "\n",
    "\n",
    "def extract_other_columns(df):#提取GPS速度和水平精度列\n",
    "    return df[[\"dateTime\", \"hacc\", \"speed\"]].copy()\n",
    "\n",
    "\n",
    "def extract_remaining_columns(df):#提取手环中的加速度和心率列\n",
    "    return df[\n",
    "        [\"dateTime\", \"BandAccX\", \"BandAccY\", \"BandAccZ\", \"rate\", \"rateZone\"]\n",
    "    ].copy()\n",
    "\n",
    "\n",
    "def XYZsplit(df):#将TYPE中的列拆分为多个新列\n",
    "    # Drop rows where 'Type' is NaN\n",
    "    df = df.dropna(subset=[\"Type\"]).copy()\n",
    "\n",
    "    # Create columns for each type\n",
    "    types = df[\"Type\"].unique()\n",
    "    for t in types:\n",
    "        for col in [\"X\", \"Y\", \"Z\"]:\n",
    "            df.loc[:, f\"{t}_{col}\"] = df.apply(\n",
    "                lambda row: row[col] if row[\"Type\"] == t else None, axis=1\n",
    "            )\n",
    "\n",
    "    # Explicitly list columns to retain, no need for Position columns\n",
    "    columns_to_keep = [\"dateTime\"] + [\n",
    "        f\"{t}_{col}\"\n",
    "        for t in types\n",
    "        for col in [\"X\", \"Y\", \"Z\"]\n",
    "        if f\"{t}_{col}\" in df.columns\n",
    "    ]\n",
    "    df = df[columns_to_keep]\n",
    "    # Round the numeric columns to the desired decimal places\n",
    "    # Uncomment and modify the line below to set the desired decimal places\n",
    "    df = df.round(6)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Convert dateTime to pd.datetime\n",
    "def convert_to_datetime(df): #将dateTime转换为pd.datetime并且创建出一个新的列，S\n",
    "    df[\"dateTime\"] = pd.to_datetime(df[\"dateTime\"])\n",
    "    # Create a new column for the second\n",
    "    df[\"Second\"] = df[\"dateTime\"].dt.floor(\"S\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def linear_columns_interpolation(df, columns):#线性插值\n",
    "    for col in columns:\n",
    "        if df[col].notnull().sum() > 1:\n",
    "            df[col] = df[col].interpolate(\n",
    "                method=\"linear\", limit_direction=\"both\", limit_area=\"inside\"\n",
    "            )\n",
    "    return df\n",
    "\n",
    "\n",
    "def b_and_ffill_columns_interpolation(df, columns):#先用最近非空数值向后填充，再向前填充\n",
    "    for col in columns:\n",
    "        df[col] = df[col].bfill().ffill()\n",
    "    return df\n",
    "\n",
    "\n",
    "def limited_columns_interpolation(df, columns):#先用线性插值法对前后20个数值进行插值，剩余再用0填充\n",
    "    for col in columns:\n",
    "        if df[col].notnull().sum() > 1:\n",
    "            df[col] = df[col].interpolate(method=\"linear\", limit_direction=\"both\", limit=20)\n",
    "            df[col] = df[col].fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def orientation_interpolation(df, columns):#对朝向进行插值\n",
    "    # Check if the dataframe has the required columns\n",
    "    length = len(df)\n",
    "    if not all(col in df.columns for col in columns):\n",
    "        raise ValueError(\"DataFrame does not contain all required columns\")\n",
    "\n",
    "    # Convert the orientation columns to Rotation objects, handling NaNs\n",
    "    indices = []\n",
    "    rotations = []\n",
    "    for index, row in df[columns].iterrows():\n",
    "        if not row.isnull().any():\n",
    "            indices.append(index)\n",
    "            rotations.append(R.from_euler(\"xyz\", row, degrees=True))\n",
    "\n",
    "    # Check if there are at least two valid data points to perform interpolation\n",
    "    if len(indices) < 2:\n",
    "        raise ValueError(\"Not enough valid data points to perform interpolation\")\n",
    "\n",
    "    slerp = Slerp(indices, R.from_quat([r.as_quat() for r in rotations]))\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i][columns].isnull().any():\n",
    "            # Ensure the interpolation index is within the valid range\n",
    "            if i >= indices[0] and i <= indices[-1]:\n",
    "                df.loc[i, columns] = slerp([i])[0].as_euler(\"xyz\", degrees=True)\n",
    "\n",
    "    # Fill any remaining NaNs (if interpolation limit is reached) with zeros or other strategy\n",
    "    df[columns] = df[columns].fillna(0)\n",
    "    df = df[:length]\n",
    "\n",
    "    return df\n",
    "\n",
    "distance_check_columns = [\n",
    "    \"Acceleration_X\",\n",
    "    \"Acceleration_Y\",\n",
    "    \"Acceleration_Z\",\n",
    "    \"MagneticField_X\",\n",
    "    \"MagneticField_Y\",\n",
    "    \"MagneticField_Z\",\n",
    "    \"Orientation_X\",\n",
    "    \"Orientation_Y\",\n",
    "    \"Orientation_Z\",\n",
    "    \"AngularVelocity_X\",\n",
    "    \"AngularVelocity_Y\",\n",
    "    \"AngularVelocity_Z\",\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    \"altitude\",\n",
    "]\n",
    "\n",
    "distance_thresholds = {\n",
    "    \"Acceleration_X\": 50.0,   # m/s^2\n",
    "    \"Acceleration_Y\": 50.0,   # m/s^2\n",
    "    \"Acceleration_Z\": 50.0,   # m/s^2\n",
    "    \"MagneticField_X\": 60.0,  # μT\n",
    "    \"MagneticField_Y\": 60.0,  # μT\n",
    "    \"MagneticField_Z\": 60.0,  # μT\n",
    "    \"Orientation_X\": 360.0,   # 方位角，° (0-360度)\n",
    "    \"Orientation_Y\": 90.0,    # 俯仰，° (-90到90度)\n",
    "    \"Orientation_Z\": 180.0,   # 滚转，° (-180到180度)\n",
    "    \"AngularVelocity_X\": 500.0, # °/s\n",
    "    \"AngularVelocity_Y\": 500.0, # °/s\n",
    "    \"AngularVelocity_Z\": 500.0, # °/s\n",
    "    \"longitude\": 180.0,       # 地理经度范围 (-180到180度)\n",
    "    \"latitude\": 90.0,         # 地理纬度范围 (-90到90度)\n",
    "    \"altitude\": 8848.0,       # 地理高度，假设不超过珠穆朗玛峰高度，单位为米\n",
    "}\n",
    "\n",
    "def distance_based_outlier_detection(df, columns, threshold):#基于距离的异常值检测\n",
    "    if not all(col in df.columns for col in columns):\n",
    "        raise ValueError(\"DataFrame does not contain all required columns\")\n",
    "\n",
    "    outlier_context_indices = set()\n",
    "    all_outliers = set()\n",
    "\n",
    "    for col in columns:\n",
    "        non_nan_df = df[col].dropna()\n",
    "        non_nan_indices = non_nan_df.index\n",
    "\n",
    "        for i in range(len(non_nan_indices)):\n",
    "            idx = non_nan_indices[i]\n",
    "            if i >= 5:\n",
    "                mean_value = non_nan_df.iloc[i-5:i].mean()\n",
    "            else:\n",
    "                mean_value = non_nan_df.iloc[:i].mean()\n",
    "\n",
    "            if abs(non_nan_df.loc[idx] - mean_value) > threshold[col]:\n",
    "                all_outliers.add(idx)\n",
    "                context = [idx]\n",
    "                if i - 1 >= 0:\n",
    "                    context.insert(0, non_nan_indices[i - 1])\n",
    "                if i - 2 >= 0:\n",
    "                    context.insert(0, non_nan_indices[i - 2])\n",
    "                if i + 1 < len(non_nan_indices):\n",
    "                    context.append(non_nan_indices[i + 1])\n",
    "                if i + 2 < len(non_nan_indices):\n",
    "                    context.append(non_nan_indices[i + 2])\n",
    "\n",
    "                if len(context) >= 4:\n",
    "                    if len(context) == 4:\n",
    "                        context.append(2)\n",
    "                    else:\n",
    "                        context = context[:4]\n",
    "                        context.append(2)\n",
    "                    outlier_context_indices.add(tuple(context))\n",
    "\n",
    "\n",
    "    return sorted(all_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试用例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"Acceleration_X\": [0, 1, np.nan, np.nan, np.nan, np.nan, 20, 3, 50, 1],\n",
    "    \"Acceleration_Y\": [0, 0, 1, 0, 10, 0, 0, 1, 0, 2],\n",
    "    \"Acceleration_Z\": [0, 1, 2, 0, 0, 10, 0, 1, 1, 3],\n",
    "    \"MagneticField_X\": [30, 30, 30, 30, 30, 30, 30, 30, 100, 30],\n",
    "    \"MagneticField_Y\": [40, 40, 40, 40, 40, 40, 40, 40, 150, 40],\n",
    "    \"MagneticField_Z\": [50, 50, 50, 50, 50, 50, 50, 50, 200, 50],\n",
    "    \"Orientation_X\": [0, 45, 90, 135, 180, 225, 270, 315, 360, 45],\n",
    "    \"Orientation_Y\": [0, 10, 20, 30, 40, 50, 60, 70, 80, 10],\n",
    "    \"Orientation_Z\": [0, -10, -20, -30, -40, -50, -60, -70, -80, -10],\n",
    "    \"AngularVelocity_X\": [0, 0, 0, 0, 0, 0, 0, 0, 5000, 0],\n",
    "    \"AngularVelocity_Y\": [0, 0, 0, 0, 0, 0, 0, 0, 3000, 0],\n",
    "    \"AngularVelocity_Z\": [0, 0, 0, 0, 0, 0, 0, 0, 600, 0],\n",
    "    \"longitude\": [0, 0, 0, 0, 0, 0, 0, 0, 180, 0],\n",
    "    \"latitude\": [0, 0, 0, 0, 0, 0, 0, 0, 90, 0],\n",
    "    \"altitude\": [0, 0, 0, 0, 0, 0, 0, 0, 9000, 0],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "threshold = {\n",
    "    \"Acceleration_X\": 1.0,\n",
    "    \"Acceleration_Y\": 5.0,\n",
    "    \"Acceleration_Z\": 5.0,\n",
    "    \"MagneticField_X\": 50.0,\n",
    "    \"MagneticField_Y\": 50.0,\n",
    "    \"MagneticField_Z\": 50.0,\n",
    "    \"Orientation_X\": 100.0,\n",
    "    \"Orientation_Y\": 20.0,\n",
    "    \"Orientation_Z\": 20.0,\n",
    "    \"AngularVelocity_X\": 1000.0,\n",
    "    \"AngularVelocity_Y\": 1000.0,\n",
    "    \"AngularVelocity_Z\": 300.0,\n",
    "    \"longitude\": 90.0,\n",
    "    \"latitude\": 45.0,\n",
    "    \"altitude\": 1000.0,\n",
    "}\n",
    "\n",
    "all_outliers= distance_based_outlier_detection(df, columns=threshold.keys(), threshold=threshold)\n",
    "all_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XYZ变量命名规则：变量名_X\n",
    "mat数据由：XYZ数据，地理数据和剩余数据以及时间戳构成。上述所有的data均有时间戳做主元。清洗方法给在下面\n",
    "全部线性插值列：MagneticField_X\tMagneticField_Y\tMagneticField_Z\n",
    "有限线性插值列： Acceleration_X\tAcceleration_Y\tAcceleration_Z AngularVelocity_X\tAngularVelocity_Y\tAngularVelocity_Z\n",
    "方位角特殊插值： Orientation_X\tOrientation_Y\tOrientation_Z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mat_data(df):\n",
    "    df = remove_outliers_and_apply_thresholds(df, columns_to_check, thresholds)\n",
    "    data = convert_to_datetime(df)\n",
    "    XYZdata = extract_XYZcolumns(data)\n",
    "    XYZdata_splited = XYZsplit(XYZdata)\n",
    "    remain_data = data.drop(columns=[\"X\", \"Y\", \"Z\", \"Type\"])\n",
    "    XYZdata_splited.set_index(\"dateTime\", inplace=True)\n",
    "    XYZdata_splited = XYZdata_splited.groupby(\"dateTime\").mean()\n",
    "    XYZdata_splited.drop(\n",
    "        columns=[\"Position_X\", \"Position_Y\", \"Position_Z\"], inplace=True\n",
    "    )\n",
    "    XYZdata_splited.reset_index(inplace=True)\n",
    "    t = pd.merge(remain_data, XYZdata_splited, on=\"dateTime\", how=\"outer\")\n",
    "    context_indices = distance_based_outlier_detection(t, distance_check_columns, distance_thresholds)\n",
    "    print(context_indices)\n",
    "    t=t.drop(context_indices)\n",
    "    t = linear_columns_interpolation(\n",
    "        t,\n",
    "        columns=[\n",
    "            \"MagneticField_X\",\n",
    "            \"MagneticField_Y\",\n",
    "            \"MagneticField_Z\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"altitude\",\n",
    "            \"course\",\n",
    "            \"speed\",\n",
    "        ],\n",
    "    )\n",
    "    t = limited_columns_interpolation(\n",
    "        t,\n",
    "        columns=[\n",
    "            \"Acceleration_X\",\n",
    "            \"Acceleration_Y\",\n",
    "            \"Acceleration_Z\",\n",
    "            \"AngularVelocity_X\",\n",
    "            \"AngularVelocity_Y\",\n",
    "            \"AngularVelocity_Z\",\n",
    "        ],\n",
    "    )\n",
    "    t = orientation_interpolation(\n",
    "        t, columns=[\"Orientation_X\", \"Orientation_Y\", \"Orientation_Z\"]\n",
    "    )\n",
    "    t = b_and_ffill_columns_interpolation(t, columns=[\"hacc\"])\n",
    "    mat_columns = [\n",
    "        \"MagneticField_X\",\n",
    "        \"MagneticField_Y\",\n",
    "        \"MagneticField_Z\",\n",
    "        \"Acceleration_X\",\n",
    "        \"Acceleration_Y\",\n",
    "        \"Acceleration_Z\",\n",
    "        \"AngularVelocity_X\",\n",
    "        \"AngularVelocity_Y\",\n",
    "        \"AngularVelocity_Z\",\n",
    "        \"Orientation_X\",\n",
    "        \"Orientation_Y\",\n",
    "        \"Orientation_Z\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"altitude\",\n",
    "        \"course\",\n",
    "        \"hacc\",\n",
    "        \"speed\",\n",
    "    ]\n",
    "    t[mat_columns] = t[mat_columns].bfill().ffill()\n",
    "    t.drop(columns=[\"Second\"], inplace=True)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sydwi\\AppData\\Local\\Temp\\ipykernel_24272\\4161975795.py:83: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  df[\"Second\"] = df[\"dateTime\"].dt.floor(\"S\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_mat_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m, in \u001b[0;36mprocess_mat_data\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m convert_to_datetime(df)\n\u001b[0;32m      4\u001b[0m XYZdata \u001b[38;5;241m=\u001b[39m extract_XYZcolumns(data)\n\u001b[1;32m----> 5\u001b[0m XYZdata_splited \u001b[38;5;241m=\u001b[39m \u001b[43mXYZsplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXYZdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m remain_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      7\u001b[0m XYZdata_splited\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdateTime\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[7], line 60\u001b[0m, in \u001b[0;36mXYZsplit\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m types:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m---> 60\u001b[0m         df\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mType\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Explicitly list columns to retain, no need for Position columns\u001b[39;00m\n\u001b[0;32m     65\u001b[0m columns_to_keep \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdateTime\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m [\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m types\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     70\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\pandas\\core\\frame.py:10361\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10347\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10349\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10350\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10351\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10359\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10360\u001b[0m )\n\u001b[1;32m> 10361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[7], line 61\u001b[0m, in \u001b[0;36mXYZsplit.<locals>.<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m types:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     60\u001b[0m         df\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m---> 61\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m row: row[col] \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mType\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m t \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     62\u001b[0m         )\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Explicitly list columns to retain, no need for Position columns\u001b[39;00m\n\u001b[0;32m     65\u001b[0m columns_to_keep \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdateTime\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m [\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m types\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     70\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\pandas\\core\\series.py:1090\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1087\u001b[0m check_dict_or_set_indexers(key)\n\u001b[0;32m   1088\u001b[0m key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1090\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mEllipsis\u001b[39;49m:\n\u001b[0;32m   1091\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mor\u001b[39;00m warn_copy_on_write():\n\u001b[0;32m   1092\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = process_mat_data(df_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sydwi\\AppData\\Local\\Temp\\ipykernel_24272\\4161975795.py:83: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  df[\"Second\"] = df[\"dateTime\"].dt.floor(\"S\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3293, 3401, 3989, 4082, 4160, 4793, 4822, 4853, 4884, 4885, 4976, 5054, 5069, 5115, 5146, 5223, 5224, 5379, 5395, 5458, 5535, 5581, 5597, 5612, 5689, 5736, 5799, 5815, 5875, 5891, 5892, 5921, 5922, 5951, 6092, 6934, 6951, 7044, 7059, 7105, 7120, 7151, 7166, 7243, 7259, 7367, 7368, 7413, 7429, 7475, 7491, 7506, 7552, 7569, 7660, 7768, 7783, 7908, 7923, 7984, 8077, 8247, 8510, 8679, 8851, 9021, 9114, 9190, 9206, 9207, 9222, 9267, 9361, 9532, 10042, 10211, 10380, 10720, 11061, 11167, 11183, 11321, 11492, 11662, 11676, 11677, 11827, 11843, 11858, 11997, 12105, 12198, 13523, 13772, 14078, 14230, 14306, 14551, 14799, 15045, 15212, 15289, 15460, 15538, 15706, 15707, 15772, 16244, 16361, 16719, 16748, 17167, 19451, 20225, 21957, 22018, 22112, 22128, 22282, 22299, 22313, 22360, 22421, 22436, 22651, 22728]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sydwi\\AppData\\Local\\Temp\\ipykernel_24272\\4161975795.py:83: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  df[\"Second\"] = df[\"dateTime\"].dt.floor(\"S\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26264, 26477, 26478, 26492, 26631, 26648, 26664]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sydwi\\AppData\\Local\\Temp\\ipykernel_24272\\4161975795.py:83: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  df[\"Second\"] = df[\"dateTime\"].dt.floor(\"S\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3654, 3681, 3712, 3739, 3768, 3793, 3823, 3825, 3879, 3966, 3995, 4001, 4023, 4051, 4058, 4079, 4106, 4107, 4134, 4166, 4173, 4191, 4221, 4240, 4250, 4270, 4277, 4278, 4306, 4335, 4343, 4362, 4390, 4418, 4476, 4503, 4533, 4562, 4648, 4705, 4735, 4761, 4792, 4848, 4877, 4931, 5018, 5048, 5102, 5130, 5188, 5219, 5275, 5303, 5331, 5443, 5473, 5502, 5670, 5700, 5729, 5730, 5815, 5843, 5874, 5904, 5958, 5987, 6102, 6128, 6158, 6597, 6614, 6876, 6891, 6983, 6998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sydwi\\AppData\\Local\\Temp\\ipykernel_24272\\4161975795.py:83: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  df[\"Second\"] = df[\"dateTime\"].dt.floor(\"S\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sydwi\\AppData\\Local\\Temp\\ipykernel_24272\\4161975795.py:83: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  df[\"Second\"] = df[\"dateTime\"].dt.floor(\"S\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8561, 8686, 8980, 9090, 9153, 9260, 9601, 9661, 13501, 17488, 19175, 19191, 19252, 19268, 19406, 35186, 35189, 35192, 35207]\n"
     ]
    }
   ],
   "source": [
    "for i in range(df_list.__len__()):\n",
    "    df_list[i] = process_mat_data(df_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateTime</th>\n",
       "      <th>BandAccX</th>\n",
       "      <th>BandAccY</th>\n",
       "      <th>BandAccZ</th>\n",
       "      <th>altitude</th>\n",
       "      <th>course</th>\n",
       "      <th>hacc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>speed</th>\n",
       "      <th>...</th>\n",
       "      <th>Acceleration_Z</th>\n",
       "      <th>MagneticField_X</th>\n",
       "      <th>MagneticField_Y</th>\n",
       "      <th>MagneticField_Z</th>\n",
       "      <th>Orientation_X</th>\n",
       "      <th>Orientation_Y</th>\n",
       "      <th>Orientation_Z</th>\n",
       "      <th>AngularVelocity_X</th>\n",
       "      <th>AngularVelocity_Y</th>\n",
       "      <th>AngularVelocity_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34275</td>\n",
       "      <td>34275.000000</td>\n",
       "      <td>34275.000000</td>\n",
       "      <td>34275.000000</td>\n",
       "      <td>34275.000</td>\n",
       "      <td>34275.0</td>\n",
       "      <td>34275.000</td>\n",
       "      <td>3.427500e+04</td>\n",
       "      <td>34275.0000</td>\n",
       "      <td>34275.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34275.000000</td>\n",
       "      <td>34275.000000</td>\n",
       "      <td>34275.000000</td>\n",
       "      <td>34275.000000</td>\n",
       "      <td>34275.000000</td>\n",
       "      <td>34275.000000</td>\n",
       "      <td>34275.000000</td>\n",
       "      <td>34275.000000</td>\n",
       "      <td>34275.000000</td>\n",
       "      <td>34275.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2024-06-06 11:51:34.376754176</td>\n",
       "      <td>3216.697575</td>\n",
       "      <td>1894.099976</td>\n",
       "      <td>245.700238</td>\n",
       "      <td>69.448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.642</td>\n",
       "      <td>5.233552e+01</td>\n",
       "      <td>4.8633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.108203</td>\n",
       "      <td>-0.351952</td>\n",
       "      <td>-23.004456</td>\n",
       "      <td>-14.385113</td>\n",
       "      <td>15.351362</td>\n",
       "      <td>-44.599906</td>\n",
       "      <td>-38.774608</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.001087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2024-06-06 11:47:48.119000</td>\n",
       "      <td>-17238.810865</td>\n",
       "      <td>-7455.121460</td>\n",
       "      <td>-2397.964055</td>\n",
       "      <td>69.448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.642</td>\n",
       "      <td>5.233552e+01</td>\n",
       "      <td>4.8633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.928432</td>\n",
       "      <td>-44.156250</td>\n",
       "      <td>-66.337502</td>\n",
       "      <td>-49.181252</td>\n",
       "      <td>-179.974899</td>\n",
       "      <td>-89.977197</td>\n",
       "      <td>-179.985885</td>\n",
       "      <td>-0.780572</td>\n",
       "      <td>-1.933587</td>\n",
       "      <td>-2.590588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2024-06-06 11:49:40.766500096</td>\n",
       "      <td>3208.663364</td>\n",
       "      <td>1191.412205</td>\n",
       "      <td>-64.201167</td>\n",
       "      <td>69.448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.642</td>\n",
       "      <td>5.233552e+01</td>\n",
       "      <td>4.8633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047956</td>\n",
       "      <td>-16.139532</td>\n",
       "      <td>-36.937500</td>\n",
       "      <td>-33.375000</td>\n",
       "      <td>-67.487360</td>\n",
       "      <td>-79.191614</td>\n",
       "      <td>-119.447541</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.005256</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2024-06-06 11:51:37.135000064</td>\n",
       "      <td>4003.707353</td>\n",
       "      <td>1717.656182</td>\n",
       "      <td>334.474862</td>\n",
       "      <td>69.448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.642</td>\n",
       "      <td>5.233552e+01</td>\n",
       "      <td>4.8633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.443870</td>\n",
       "      <td>2.760000</td>\n",
       "      <td>-27.026252</td>\n",
       "      <td>-17.807813</td>\n",
       "      <td>26.370841</td>\n",
       "      <td>-52.678864</td>\n",
       "      <td>-7.213340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2024-06-06 11:53:27.738999808</td>\n",
       "      <td>4609.612535</td>\n",
       "      <td>2460.589452</td>\n",
       "      <td>647.712030</td>\n",
       "      <td>69.448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.642</td>\n",
       "      <td>5.233552e+01</td>\n",
       "      <td>4.8633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.785048</td>\n",
       "      <td>15.431251</td>\n",
       "      <td>-14.483438</td>\n",
       "      <td>3.534375</td>\n",
       "      <td>106.309270</td>\n",
       "      <td>-24.531233</td>\n",
       "      <td>0.409368</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.008976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-06-06 11:55:23.448000</td>\n",
       "      <td>17568.931588</td>\n",
       "      <td>11040.522262</td>\n",
       "      <td>3873.115102</td>\n",
       "      <td>69.448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.642</td>\n",
       "      <td>5.233552e+01</td>\n",
       "      <td>4.8633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.344778</td>\n",
       "      <td>38.193752</td>\n",
       "      <td>54.037502</td>\n",
       "      <td>45.956253</td>\n",
       "      <td>179.972149</td>\n",
       "      <td>89.731335</td>\n",
       "      <td>179.980627</td>\n",
       "      <td>1.401754</td>\n",
       "      <td>2.053029</td>\n",
       "      <td>1.120924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2464.909747</td>\n",
       "      <td>1032.361020</td>\n",
       "      <td>637.460110</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.105531e-15</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.703934</td>\n",
       "      <td>17.734701</td>\n",
       "      <td>22.651828</td>\n",
       "      <td>21.468563</td>\n",
       "      <td>98.289757</td>\n",
       "      <td>41.891892</td>\n",
       "      <td>77.667123</td>\n",
       "      <td>0.111675</td>\n",
       "      <td>0.157670</td>\n",
       "      <td>0.154381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            dateTime      BandAccX      BandAccY  \\\n",
       "count                          34275  34275.000000  34275.000000   \n",
       "mean   2024-06-06 11:51:34.376754176   3216.697575   1894.099976   \n",
       "min       2024-06-06 11:47:48.119000 -17238.810865  -7455.121460   \n",
       "25%    2024-06-06 11:49:40.766500096   3208.663364   1191.412205   \n",
       "50%    2024-06-06 11:51:37.135000064   4003.707353   1717.656182   \n",
       "75%    2024-06-06 11:53:27.738999808   4609.612535   2460.589452   \n",
       "max       2024-06-06 11:55:23.448000  17568.931588  11040.522262   \n",
       "std                              NaN   2464.909747   1032.361020   \n",
       "\n",
       "           BandAccZ   altitude   course       hacc      latitude   longitude  \\\n",
       "count  34275.000000  34275.000  34275.0  34275.000  3.427500e+04  34275.0000   \n",
       "mean     245.700238     69.448      0.0     19.642  5.233552e+01      4.8633   \n",
       "min    -2397.964055     69.448      0.0     19.642  5.233552e+01      4.8633   \n",
       "25%      -64.201167     69.448      0.0     19.642  5.233552e+01      4.8633   \n",
       "50%      334.474862     69.448      0.0     19.642  5.233552e+01      4.8633   \n",
       "75%      647.712030     69.448      0.0     19.642  5.233552e+01      4.8633   \n",
       "max     3873.115102     69.448      0.0     19.642  5.233552e+01      4.8633   \n",
       "std      637.460110      0.000      0.0      0.000  7.105531e-15      0.0000   \n",
       "\n",
       "         speed  ...  Acceleration_Z  MagneticField_X  MagneticField_Y  \\\n",
       "count  34275.0  ...    34275.000000     34275.000000     34275.000000   \n",
       "mean       0.0  ...        3.108203        -0.351952       -23.004456   \n",
       "min        0.0  ...      -39.928432       -44.156250       -66.337502   \n",
       "25%        0.0  ...       -0.047956       -16.139532       -36.937500   \n",
       "50%        0.0  ...        3.443870         2.760000       -27.026252   \n",
       "75%        0.0  ...        7.785048        15.431251       -14.483438   \n",
       "max        0.0  ...       28.344778        38.193752        54.037502   \n",
       "std        0.0  ...        5.703934        17.734701        22.651828   \n",
       "\n",
       "       MagneticField_Z  Orientation_X  Orientation_Y  Orientation_Z  \\\n",
       "count     34275.000000   34275.000000   34275.000000   34275.000000   \n",
       "mean        -14.385113      15.351362     -44.599906     -38.774608   \n",
       "min         -49.181252    -179.974899     -89.977197    -179.985885   \n",
       "25%         -33.375000     -67.487360     -79.191614    -119.447541   \n",
       "50%         -17.807813      26.370841     -52.678864      -7.213340   \n",
       "75%           3.534375     106.309270     -24.531233       0.409368   \n",
       "max          45.956253     179.972149      89.731335     179.980627   \n",
       "std          21.468563      98.289757      41.891892      77.667123   \n",
       "\n",
       "       AngularVelocity_X  AngularVelocity_Y  AngularVelocity_Z  \n",
       "count       34275.000000       34275.000000       34275.000000  \n",
       "mean            0.002457           0.003039           0.001087  \n",
       "min            -0.780572          -1.933587          -2.590588  \n",
       "25%            -0.007435          -0.005256           0.000000  \n",
       "50%             0.000000           0.000000           0.000000  \n",
       "75%             0.004312           0.003763           0.008976  \n",
       "max             1.401754           2.053029           1.120924  \n",
       "std             0.111675           0.157670           0.154381  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看是否有空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame contains NaN values:\n",
      " False\n",
      "\n",
      "Rows with NaN values:\n",
      " Empty DataFrame\n",
      "Columns: [dateTime, BandAccX, BandAccY, BandAccZ, altitude, course, hacc, latitude, longitude, speed, rate, rateZone, usage, deviceStatus, Acceleration_X, Acceleration_Y, Acceleration_Z, MagneticField_X, MagneticField_Y, MagneticField_Z, Orientation_X, Orientation_Y, Orientation_Z, AngularVelocity_X, AngularVelocity_Y, AngularVelocity_Z]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 26 columns]\n",
      "\n",
      "Count of NaN values in each column:\n",
      " dateTime             0\n",
      "BandAccX             0\n",
      "BandAccY             0\n",
      "BandAccZ             0\n",
      "altitude             0\n",
      "course               0\n",
      "hacc                 0\n",
      "latitude             0\n",
      "longitude            0\n",
      "speed                0\n",
      "rate                 0\n",
      "rateZone             0\n",
      "usage                0\n",
      "deviceStatus         0\n",
      "Acceleration_X       0\n",
      "Acceleration_Y       0\n",
      "Acceleration_Z       0\n",
      "MagneticField_X      0\n",
      "MagneticField_Y      0\n",
      "MagneticField_Z      0\n",
      "Orientation_X        0\n",
      "Orientation_Y        0\n",
      "Orientation_Z        0\n",
      "AngularVelocity_X    0\n",
      "AngularVelocity_Y    0\n",
      "AngularVelocity_Z    0\n",
      "dtype: int64\n",
      "DataFrame contains NaN values:\n",
      " False\n",
      "\n",
      "Rows with NaN values:\n",
      " Empty DataFrame\n",
      "Columns: [dateTime, BandAccX, BandAccY, BandAccZ, altitude, course, hacc, latitude, longitude, speed, rate, rateZone, usage, deviceStatus, Acceleration_X, Acceleration_Y, Acceleration_Z, MagneticField_X, MagneticField_Y, MagneticField_Z, Orientation_X, Orientation_Y, Orientation_Z, AngularVelocity_X, AngularVelocity_Y, AngularVelocity_Z]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 26 columns]\n",
      "\n",
      "Count of NaN values in each column:\n",
      " dateTime             0\n",
      "BandAccX             0\n",
      "BandAccY             0\n",
      "BandAccZ             0\n",
      "altitude             0\n",
      "course               0\n",
      "hacc                 0\n",
      "latitude             0\n",
      "longitude            0\n",
      "speed                0\n",
      "rate                 0\n",
      "rateZone             0\n",
      "usage                0\n",
      "deviceStatus         0\n",
      "Acceleration_X       0\n",
      "Acceleration_Y       0\n",
      "Acceleration_Z       0\n",
      "MagneticField_X      0\n",
      "MagneticField_Y      0\n",
      "MagneticField_Z      0\n",
      "Orientation_X        0\n",
      "Orientation_Y        0\n",
      "Orientation_Z        0\n",
      "AngularVelocity_X    0\n",
      "AngularVelocity_Y    0\n",
      "AngularVelocity_Z    0\n",
      "dtype: int64\n",
      "DataFrame contains NaN values:\n",
      " False\n",
      "\n",
      "Rows with NaN values:\n",
      " Empty DataFrame\n",
      "Columns: [dateTime, BandAccX, BandAccY, BandAccZ, altitude, course, hacc, latitude, longitude, speed, rate, rateZone, usage, deviceStatus, Acceleration_X, Acceleration_Y, Acceleration_Z, MagneticField_X, MagneticField_Y, MagneticField_Z, Orientation_X, Orientation_Y, Orientation_Z, AngularVelocity_X, AngularVelocity_Y, AngularVelocity_Z]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 26 columns]\n",
      "\n",
      "Count of NaN values in each column:\n",
      " dateTime             0\n",
      "BandAccX             0\n",
      "BandAccY             0\n",
      "BandAccZ             0\n",
      "altitude             0\n",
      "course               0\n",
      "hacc                 0\n",
      "latitude             0\n",
      "longitude            0\n",
      "speed                0\n",
      "rate                 0\n",
      "rateZone             0\n",
      "usage                0\n",
      "deviceStatus         0\n",
      "Acceleration_X       0\n",
      "Acceleration_Y       0\n",
      "Acceleration_Z       0\n",
      "MagneticField_X      0\n",
      "MagneticField_Y      0\n",
      "MagneticField_Z      0\n",
      "Orientation_X        0\n",
      "Orientation_Y        0\n",
      "Orientation_Z        0\n",
      "AngularVelocity_X    0\n",
      "AngularVelocity_Y    0\n",
      "AngularVelocity_Z    0\n",
      "dtype: int64\n",
      "DataFrame contains NaN values:\n",
      " False\n",
      "\n",
      "Rows with NaN values:\n",
      " Empty DataFrame\n",
      "Columns: [dateTime, BandAccX, BandAccY, BandAccZ, altitude, course, hacc, latitude, longitude, speed, rate, rateZone, usage, deviceStatus, Acceleration_X, Acceleration_Y, Acceleration_Z, MagneticField_X, MagneticField_Y, MagneticField_Z, AngularVelocity_X, AngularVelocity_Y, AngularVelocity_Z, Orientation_X, Orientation_Y, Orientation_Z]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 26 columns]\n",
      "\n",
      "Count of NaN values in each column:\n",
      " dateTime             0\n",
      "BandAccX             0\n",
      "BandAccY             0\n",
      "BandAccZ             0\n",
      "altitude             0\n",
      "course               0\n",
      "hacc                 0\n",
      "latitude             0\n",
      "longitude            0\n",
      "speed                0\n",
      "rate                 0\n",
      "rateZone             0\n",
      "usage                0\n",
      "deviceStatus         0\n",
      "Acceleration_X       0\n",
      "Acceleration_Y       0\n",
      "Acceleration_Z       0\n",
      "MagneticField_X      0\n",
      "MagneticField_Y      0\n",
      "MagneticField_Z      0\n",
      "AngularVelocity_X    0\n",
      "AngularVelocity_Y    0\n",
      "AngularVelocity_Z    0\n",
      "Orientation_X        0\n",
      "Orientation_Y        0\n",
      "Orientation_Z        0\n",
      "dtype: int64\n",
      "DataFrame contains NaN values:\n",
      " False\n",
      "\n",
      "Rows with NaN values:\n",
      " Empty DataFrame\n",
      "Columns: [dateTime, BandAccX, BandAccY, BandAccZ, altitude, course, hacc, latitude, longitude, speed, rate, rateZone, usage, deviceStatus, Acceleration_X, Acceleration_Y, Acceleration_Z, MagneticField_X, MagneticField_Y, MagneticField_Z, Orientation_X, Orientation_Y, Orientation_Z, AngularVelocity_X, AngularVelocity_Y, AngularVelocity_Z]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 26 columns]\n",
      "\n",
      "Count of NaN values in each column:\n",
      " dateTime             0\n",
      "BandAccX             0\n",
      "BandAccY             0\n",
      "BandAccZ             0\n",
      "altitude             0\n",
      "course               0\n",
      "hacc                 0\n",
      "latitude             0\n",
      "longitude            0\n",
      "speed                0\n",
      "rate                 0\n",
      "rateZone             0\n",
      "usage                0\n",
      "deviceStatus         0\n",
      "Acceleration_X       0\n",
      "Acceleration_Y       0\n",
      "Acceleration_Z       0\n",
      "MagneticField_X      0\n",
      "MagneticField_Y      0\n",
      "MagneticField_Z      0\n",
      "Orientation_X        0\n",
      "Orientation_Y        0\n",
      "Orientation_Z        0\n",
      "AngularVelocity_X    0\n",
      "AngularVelocity_Y    0\n",
      "AngularVelocity_Z    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in range(df_list.__len__()):\n",
    "    \n",
    "    # 检查整个数据框是否有 NaN 值\n",
    "    print(\"DataFrame contains NaN values:\\n\", df_list[i].isnull().any().any())\n",
    "\n",
    "    # 打印出含有 NaN 值的行\n",
    "    nan_rows = df_list[i][df_list[i].isnull().any(axis=1)]\n",
    "    print(\"\\nRows with NaN values:\\n\", nan_rows)\n",
    "\n",
    "    # 统计各列中 NaN 值的数量\n",
    "    nan_counts = df_list[i].isnull().sum()\n",
    "    print(\"\\nCount of NaN values in each column:\\n\", nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_merge_data_dir = os.getcwd() + '/cleaned_merge_data/'\n",
    "cleaned_merge_data_files = ['cleaned_walk_merge_raw.csv', 'cleaned_bike_merge_raw.csv', 'cleaned_run_merge_raw.csv', 'cleaned_sit_merge_raw.csv', 'cleaned_syn_merge_raw.csv']\n",
    "for i in range(df_list.__len__()):\n",
    "    df_list[i].to_csv(cleaned_merge_data_dir + cleaned_merge_data_files[i], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
